{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-17T11:32:41.227913Z",
     "start_time": "2025-09-17T11:32:41.224022Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T11:32:45.915865Z",
     "start_time": "2025-09-17T11:32:41.230426Z"
    }
   },
   "cell_type": "code",
   "source": "from utils.EmbeddingVectorizer import tfidf_vectorizer, bow_vectorizer, embedding_vectorizer",
   "id": "4a066e7820ecc337",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T11:32:45.946188Z",
     "start_time": "2025-09-17T11:32:45.917544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = pd.read_csv(\"../dataset/train_data.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/test_data.csv\")\n",
    "X_train = train_data.iloc[:, 0]\n",
    "X_test = test_data.iloc[:, 0]"
   ],
   "id": "a9330decaef52ad5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T11:32:46.318061Z",
     "start_time": "2025-09-17T11:32:45.947685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Xtrain_tfidf, Xtest_tfidf = tfidf_vectorizer(X_train=X_train, X_test=X_test)\n",
    "print(Xtrain_tfidf.shape)\n",
    "print(Xtest_tfidf.shape)"
   ],
   "id": "68327d7f10b43a64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 18450)\n",
      "(400, 18450)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T11:32:46.638978Z",
     "start_time": "2025-09-17T11:32:46.319337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Xtrain_bow, Xtest_bow = bow_vectorizer(X_train=X_train, X_test=X_test)\n",
    "print(Xtrain_bow.shape)\n",
    "print(Xtest_bow.shape)"
   ],
   "id": "3efcf62d688af2da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 18450)\n",
      "(400, 18450)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T11:32:46.646339Z",
     "start_time": "2025-09-17T11:32:46.640531Z"
    }
   },
   "cell_type": "code",
   "source": "Xtrain_tfidf[1][5]",
   "id": "d83800630d8e0841",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T11:42:55.855250Z",
     "start_time": "2025-09-17T11:35:46.259016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Xtrain_em, Xtest_em = embedding_vectorizer(X_train=X_train.to_list(), X_test=X_test.to_list())\n",
    "print(Xtrain_em.shape)\n",
    "print(Xtest_em.shape)"
   ],
   "id": "63377dc8d23ffc54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmbeddingVectorizer initialized with model: intfloat/multilingual-e5-base on device: cpu\n",
      "(1600, 768)\n",
      "(400, 768)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T11:32:07.485567Z",
     "start_time": "2025-09-17T11:32:07.035291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"Device count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"Memory: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"No GPU available\")"
   ],
   "id": "53fdded21cf4e4c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.2+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "Device count: 1\n",
      "GPU 0: NVIDIA RTX 500 Ada Generation Laptop GPU\n",
      "Memory: 3.7 GB\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T11:32:22.425374Z",
     "start_time": "2025-09-17T11:32:22.138506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    # Test 1: Tạo tensor nhỏ\n",
    "    print(\"Test 1: Creating small tensor...\")\n",
    "    x = torch.tensor([1.0, 2.0, 3.0], device='cuda')\n",
    "    print(\"✅ Success\")\n",
    "\n",
    "    # Test 2: Phép toán đơn giản\n",
    "    print(\"Test 2: Simple operation...\")\n",
    "    y = x * 2\n",
    "    print(f\"✅ Result: {y}\")\n",
    "\n",
    "    # Test 3: Tensor lớn hơn\n",
    "    print(\"Test 3: Larger tensor...\")\n",
    "    z = torch.randn(100, 100, device='cuda')\n",
    "    print(\"✅ Success\")\n",
    "\n",
    "    # Test 4: Phép nhân ma trận\n",
    "    print(\"Test 4: Matrix multiplication...\")\n",
    "    result = torch.mm(z, z.T)\n",
    "    print(\"✅ Success\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error at step: {e}\")"
   ],
   "id": "a766ebca8885519e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: Creating small tensor...\n",
      "✅ Success\n",
      "Test 2: Simple operation...\n",
      "✅ Result: tensor([2., 4., 6.], device='cuda:0')\n",
      "Test 3: Larger tensor...\n",
      "✅ Success\n",
      "Test 4: Matrix multiplication...\n",
      "✅ Success\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T18:19:16.095201Z",
     "start_time": "2025-09-17T18:19:16.058045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.cuda.empty_cache()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"CUDA context reset\")"
   ],
   "id": "79d52cabdcdd481e",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[26]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcuda\u001B[49m\u001B[43m.\u001B[49m\u001B[43mempty_cache\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch.cuda.is_available():\n\u001B[32m      3\u001B[39m     torch.cuda.synchronize()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/torch/cuda/memory.py:162\u001B[39m, in \u001B[36mempty_cache\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    151\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001B[39;00m\n\u001B[32m    152\u001B[39m \u001B[33;03mallocator so that those can be used in other GPU application and visible in\u001B[39;00m\n\u001B[32m    153\u001B[39m \u001B[33;03m`nvidia-smi`.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    159\u001B[39m \u001B[33;03m    more details about GPU memory management.\u001B[39;00m\n\u001B[32m    160\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    161\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_initialized():\n\u001B[32m--> \u001B[39m\u001B[32m162\u001B[39m     \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_C\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_cuda_emptyCache\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mRuntimeError\u001B[39m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def rf_model(trial):\n",
    "        \"\"\"\n",
    "        model random forest to find the initial accuracy before optimization\n",
    "        :param trial: the objective parameters for optuna\n",
    "        :return: first accuracy\n",
    "        \"\"\"\n",
    "        para_grid = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 100),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 5),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 2, 5),\n",
    "            \"max_features\": trial.suggest_float(\"max_features\", 0.1, 1.0),\n",
    "            \"class_weight\": trial.suggest_categorical(\"class_weight\", [None, \"balanced\"]),\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1,\n",
    "        }\n",
    "        # first train\n",
    "        rfc = RandomForestClassifier(**para_grid)\n",
    "        rfc.fit(X_train, y_train)\n",
    "        y_pred = rfc.predict(X_test)\n",
    "        score = cross_val_score(rfc, X_train, y_train, cv=5, n_jobs=-1).mean()\n",
    "        return score\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(rf_model, n_trials=20)\n",
    "\n",
    "    # Collect best parameters\n",
    "    best_parameters = study.best_params\n",
    "    print(\"Best parameters found:\")\n",
    "    for key, value in best_parameters.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "\n",
    "    # Apply to new optimized model\n",
    "    optimized_rfc = RandomForestClassifier(**best_parameters)\n",
    "    optimized_rfc.fit(X_train, y_train)\n",
    "    y_pred = optimized_rfc.predict(X_test)\n",
    "\n",
    "    # Calculate metrics then export report:\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    return y_pred, accuracy, report"
   ],
   "id": "8fb9aebcc09a48fe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
