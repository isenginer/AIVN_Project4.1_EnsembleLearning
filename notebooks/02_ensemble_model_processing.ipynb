{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# PROJECT 4.1 - ENSEMBLE LEARNING TECHNIQUE\n",
    "## `Ensemble Model Processing:`\n",
    "`DecisionTree, AdaBoost, XGBoost, GradienBoost & Adaboost test`"
   ],
   "id": "f2243d2673091f46"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T10:14:01.624640Z",
     "start_time": "2025-09-25T10:14:01.391668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# FOR PROJECT ROOT\n",
    "# Setup cell\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('../')\n",
    "\n",
    "# Verify path\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Python path includes:\", [p for p in sys.path if 'Project' in p])"
   ],
   "id": "b9df5ea8e12988f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /media/anhvt/DATA/10_AIO_VN/AIOVN_Main/Project 4.1_Ensemble Learning/notebooks\n",
      "Python path includes: ['/media/anhvt/DATA/10_AIO_VN/AIOVN_Main/Project 4.1_Ensemble Learning', '/media/anhvt/DATA/10_AIO_VN/AIOVN_Main/Project 4.1_Ensemble Learning/notebooks']\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Library",
   "id": "9d2236e9ec669f90"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-25T10:14:02.158699Z",
     "start_time": "2025-09-25T10:14:01.632804Z"
    }
   },
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "import optuna"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Import Data",
   "id": "52189769b38fe025"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Use `joblib` to export embedding vectorizer",
   "id": "b74d87477b686c40"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T10:14:53.456060Z",
     "start_time": "2025-09-25T10:14:53.302720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.data_storage import load_all_vectorizers\n",
    "# tfidf_data, bow_data, embeddings_data, targets = load_all_vectorizers()\n",
    "Xtrain_tfidf, Xtest_tfidf, Xtrain_bow, Xtest_bow, Xtrain_em, Xtest_em, y_train, y_test = load_all_vectorizers()"
   ],
   "id": "c76b1c686155bd03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully loaded all vectorizers and vector representations\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T10:15:08.879504Z",
     "start_time": "2025-09-25T10:15:08.874689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(Xtrain_tfidf.shape)\n",
    "print(Xtest_tfidf.shape)"
   ],
   "id": "6d179992b3a664c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 18450)\n",
      "(400, 18450)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Test Model",
   "id": "fe393ed91b8faeca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:31:41.065331Z",
     "start_time": "2025-09-24T14:31:41.057734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decision_tree_model(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    This model to verify the accuracy of the decision tree in classification model\n",
    "    :return: prediction, accuracy of the decision tree\n",
    "    \"\"\"\n",
    "    param_grid = {\n",
    "        \"max_depth\": 10,\n",
    "        \"min_samples_split\": 20,\n",
    "        \"min_samples_leaf\": 10,\n",
    "        \"criterion\": \"gini\",\n",
    "        \"max_features\": \"sqrt\",\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "    dtc = DecisionTreeClassifier(**param_grid)\n",
    "    dtc.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = dtc.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    return y_pred, score, report"
   ],
   "id": "5040c35be6ddb584",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:31:41.479934Z",
     "start_time": "2025-09-24T14:31:41.122598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Decision Tree with Empirical Parameters...\")\n",
    "_, dt_tf_accuracy, dt_tf_report = decision_tree_model(Xtrain_tfidf, Xtest_tfidf, y_train, y_test)\n",
    "_, dt_bow_accuracy, dt_bow_report = decision_tree_model(Xtrain_bow, Xtest_bow, y_train, y_test)\n",
    "_, dt_em_accuracy, dt_em_report = decision_tree_model(Xtrain_em, Xtest_em, y_train, y_test)\n",
    "\n",
    "print(f\" TfIdf vectorizer with DT accuracy: {dt_tf_accuracy}\")\n",
    "print(f\" BoW vectorizer with DT accuracy: {dt_bow_accuracy}\")\n",
    "print(f\" Emb. vectorizer with DT accuracy: {dt_em_accuracy}\")\n",
    "\n",
    "print(f\" TfIdf vectorizer with DT report: \\n{dt_tf_report}\")\n",
    "print(f\" BoW vectorizer with DT report: \\n{dt_bow_report}\")\n",
    "print(f\" Emb. vectorizer with DT report: \\n{dt_em_report}\")"
   ],
   "id": "d7c9aaf057e7883e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with Empirical Parameters...\n",
      " TfIdf vectorizer with DT accuracy: 0.4675\n",
      " BoW vectorizer with DT accuracy: 0.46\n",
      " Emb. vectorizer with DT accuracy: 0.5475\n",
      " TfIdf vectorizer with DT report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.35      0.31      0.33        59\n",
      "           2       0.49      0.24      0.32        75\n",
      "           3       0.69      0.50      0.58       113\n",
      "           4       0.41      0.86      0.56       109\n",
      "           5       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.47       400\n",
      "   macro avg       0.32      0.32      0.30       400\n",
      "weighted avg       0.45      0.47      0.42       400\n",
      "\n",
      " BoW vectorizer with DT report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.33      0.37      0.35        59\n",
      "           2       0.49      0.23      0.31        75\n",
      "           3       0.68      0.46      0.55       113\n",
      "           4       0.42      0.85      0.56       109\n",
      "           5       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.46       400\n",
      "   macro avg       0.32      0.32      0.30       400\n",
      "weighted avg       0.45      0.46      0.42       400\n",
      "\n",
      " Emb. vectorizer with DT report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.48      0.58      0.52        59\n",
      "           2       0.50      0.52      0.51        75\n",
      "           3       0.73      0.64      0.68       113\n",
      "           4       0.54      0.63      0.58       109\n",
      "           5       0.19      0.14      0.16        35\n",
      "\n",
      "    accuracy                           0.55       400\n",
      "   macro avg       0.41      0.42      0.41       400\n",
      "weighted avg       0.54      0.55      0.54       400\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:40:27.763064Z",
     "start_time": "2025-09-24T14:40:27.759334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def random_forest_model(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Random Forest model shall learn the data from Vectorizers (TfIdf, BoW, EmbeddingVectorizer) then perform the trial on test set. After learning, from test set, the model will raise the error value then compare the performance of Random Forest to each method\n",
    "    :return accuracy report & classification report for model with each method\n",
    "    \"\"\"\n",
    "    para_grid = {\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 15,\n",
    "        \"min_samples_split\": 10,\n",
    "        \"min_samples_leaf\":5,\n",
    "        \"max_features\": \"sqrt\",\n",
    "        \"oob_score\": True\n",
    "    }\n",
    "    # first train\n",
    "    rfc = RandomForestClassifier(**para_grid)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    y_pred = rfc.predict(X_test)\n",
    "\n",
    "    # Calculate metrics then export report:\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    return y_pred, accuracy, report"
   ],
   "id": "eeaee0abaafab5f8",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:40:34.410261Z",
     "start_time": "2025-09-24T14:40:28.927566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Random Forest with Empirical Parameters...\")\n",
    "_, rf_tf_accuracy, rf_tf_report = random_forest_model(Xtrain_tfidf, Xtest_tfidf, y_train, y_test)\n",
    "_, rf_bow_accuracy, rf_bow_report = random_forest_model(Xtrain_bow, Xtest_bow, y_train, y_test)\n",
    "_, rf_em_accuracy, rf_em_report = random_forest_model(Xtrain_em, Xtest_em, y_train, y_test)\n",
    "\n",
    "print(f\" TfIdf vectorizer with RF accuracy: {rf_tf_accuracy}\")\n",
    "print(f\" BoW vectorizer with RF accuracy: {rf_bow_accuracy}\")\n",
    "print(f\" Emb. vectorizer with RF accuracy: {rf_em_accuracy}\")\n",
    "\n",
    "print(f\" TfIdf vectorizer with RF report: \\n{rf_tf_report}\")\n",
    "print(f\" BoW vectorizer with RF report: \\n{rf_bow_report}\")\n",
    "print(f\" Emb. vectorizer with RF report: \\n{rf_em_report}\")"
   ],
   "id": "1db339c1eb159cfd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Empirical Parameters...\n",
      " TfIdf vectorizer with RF accuracy: 0.7275\n",
      " BoW vectorizer with RF accuracy: 0.7325\n",
      " Emb. vectorizer with RF accuracy: 0.8175\n",
      " TfIdf vectorizer with RF report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.98      0.85      0.91        59\n",
      "           2       0.76      0.59      0.66        75\n",
      "           3       0.84      0.82      0.83       113\n",
      "           4       0.58      0.95      0.72       109\n",
      "           5       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.73       400\n",
      "   macro avg       0.53      0.54      0.52       400\n",
      "weighted avg       0.68      0.73      0.69       400\n",
      "\n",
      " BoW vectorizer with RF report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       1.00      0.83      0.91        59\n",
      "           2       0.77      0.57      0.66        75\n",
      "           3       0.86      0.86      0.86       113\n",
      "           4       0.57      0.95      0.71       109\n",
      "           5       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.73       400\n",
      "   macro avg       0.53      0.54      0.52       400\n",
      "weighted avg       0.69      0.73      0.69       400\n",
      "\n",
      " Emb. vectorizer with RF report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.92      0.97      0.94        59\n",
      "           2       0.69      0.83      0.75        75\n",
      "           3       0.93      0.93      0.93       113\n",
      "           4       0.76      0.94      0.84       109\n",
      "           5       1.00      0.03      0.06        35\n",
      "\n",
      "    accuracy                           0.82       400\n",
      "   macro avg       0.72      0.61      0.59       400\n",
      "weighted avg       0.82      0.82      0.78       400\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:31:54.384939Z",
     "start_time": "2025-09-24T14:31:54.379025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ada_boost_model(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    This model to verify the accuracy of the ada_boost in classification model\n",
    "    :return: prediction, accuracy of the adaboost in classification model\n",
    "    \"\"\"\n",
    "    param_grid = {\n",
    "        \"n_estimators\": 100,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"algorithm\": \"SAMME\",\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "    adb = AdaBoostClassifier(**param_grid)\n",
    "    adb.fit(X_train, y_train)\n",
    "\n",
    "    # fit the parameters then report\n",
    "    y_pred = adb.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    return y_pred, score, report"
   ],
   "id": "d01889a2de7b25b2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:33:25.803545Z",
     "start_time": "2025-09-24T14:31:54.440040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"AdaBoost with Empirical Parameters...\")\n",
    "_, ada_tf_accuracy, ada_tf_report = ada_boost_model(Xtrain_tfidf, Xtest_tfidf, y_train, y_test)\n",
    "_, ada_bow_accuracy, ada_bow_report = ada_boost_model(Xtrain_bow, Xtest_bow, y_train, y_test)\n",
    "_, ada_em_accuracy, ada_em_report = ada_boost_model(Xtrain_em, Xtest_em, y_train, y_test)\n",
    "\n",
    "print(f\" TfIdf vectorizer with AdaBoost accuracy: {ada_tf_accuracy}\")\n",
    "print(f\" BoW vectorizer with AdaBoost accuracy: {ada_bow_accuracy}\")\n",
    "print(f\" Emb. vectorizer with AdaBoost accuracy: {ada_em_accuracy}\")\n",
    "\n",
    "print(f\" TfIdf vectorizer with AdaBoost report: \\n{ada_tf_report}\")\n",
    "print(f\" BoW vectorizer with AdaBoost report: \\n{ada_bow_report}\")\n",
    "print(f\" Emb. vectorizer with AdaBoost report: \\n{ada_em_report}\")"
   ],
   "id": "de9d7f98c41762af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost with Empirical Parameters...\n",
      " TfIdf vectorizer with AdaBoost accuracy: 0.5\n",
      " BoW vectorizer with AdaBoost accuracy: 0.5\n",
      " Emb. vectorizer with AdaBoost accuracy: 0.7175\n",
      " TfIdf vectorizer with AdaBoost report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       1.00      0.37      0.54        59\n",
      "           2       0.00      0.00      0.00        75\n",
      "           3       0.86      0.63      0.72       113\n",
      "           4       0.36      0.98      0.53       109\n",
      "           5       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.50       400\n",
      "   macro avg       0.37      0.33      0.30       400\n",
      "weighted avg       0.49      0.50      0.43       400\n",
      "\n",
      " BoW vectorizer with AdaBoost report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       1.00      0.39      0.56        59\n",
      "           2       0.00      0.00      0.00        75\n",
      "           3       0.86      0.62      0.72       113\n",
      "           4       0.36      0.98      0.53       109\n",
      "           5       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.50       400\n",
      "   macro avg       0.37      0.33      0.30       400\n",
      "weighted avg       0.49      0.50      0.43       400\n",
      "\n",
      " Emb. vectorizer with AdaBoost report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.78      0.86      0.82        59\n",
      "           2       0.64      0.65      0.65        75\n",
      "           3       0.89      0.76      0.82       113\n",
      "           4       0.62      0.92      0.74       109\n",
      "           5       1.00      0.03      0.06        35\n",
      "\n",
      "    accuracy                           0.72       400\n",
      "   macro avg       0.66      0.54      0.51       400\n",
      "weighted avg       0.74      0.72      0.68       400\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:43:00.238281Z",
     "start_time": "2025-09-24T14:43:00.234618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gradient_boost_model(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    This model to verify the accuracy of the gradient boost in classification model\n",
    "    :return: prediction, accuracy of the gradient boost in classification model\n",
    "    \"\"\"\n",
    "    param_grid = {\n",
    "        \"max_depth\": 5,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"subsample\": 0.8,\n",
    "        \"min_samples_split\": 20, # 20-100\n",
    "        \"min_samples_leaf\": 10, # 10-20\n",
    "        \"validation_fraction\": 0.1 # 0.1-0.2\n",
    "        }\n",
    "    gb = GradientBoostingClassifier(**param_grid)\n",
    "    gb.fit(X_train, y_train)\n",
    "\n",
    "    # fit the parameters then report\n",
    "    y_pred = gb.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    return y_pred, score, report"
   ],
   "id": "740ef5796aa89650",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T15:02:14.218466Z",
     "start_time": "2025-09-24T14:43:05.465587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Gradient Boost with Empirical Parameters...\")\n",
    "_, gb_tf_accuracy, gb_tf_report = gradient_boost_model(Xtrain_tfidf, Xtest_tfidf, y_train, y_test)\n",
    "_, gb_bow_accuracy, gb_bow_report = gradient_boost_model(Xtrain_bow, Xtest_bow, y_train, y_test)\n",
    "_, gb_em_accuracy, gb_em_report = gradient_boost_model(Xtrain_em, Xtest_em, y_train, y_test)\n",
    "\n",
    "print(f\" TfIdf vectorizer with GradientBoost accuracy: {gb_tf_accuracy}\")\n",
    "print(f\" BoW vectorizer with GradientBoost accuracy: {gb_bow_accuracy}\")\n",
    "print(f\" Emb. vectorizer with GradientBoost accuracy: {gb_em_accuracy}\")\n",
    "\n",
    "print(f\" TfIdf vectorizer with GradientBoost report: \\n{gb_tf_report}\")\n",
    "print(f\" BoW vectorizer with GradientBoost report: \\n{gb_bow_report}\")\n",
    "print(f\" Emb. vectorizer with GradientBoost report: \\n{gb_em_report}\")"
   ],
   "id": "1d6740732317d426",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost with Empirical Parameters...\n",
      " TfIdf vectorizer with GradientBoost accuracy: 0.8125\n",
      " BoW vectorizer with GradientBoost accuracy: 0.7975\n",
      " Emb. vectorizer with GradientBoost accuracy: 0.8325\n",
      " TfIdf vectorizer with GradientBoost report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.93      0.97      0.95        59\n",
      "           2       0.77      0.80      0.78        75\n",
      "           3       0.89      0.82      0.86       113\n",
      "           4       0.75      0.92      0.82       109\n",
      "           5       0.68      0.43      0.53        35\n",
      "\n",
      "    accuracy                           0.81       400\n",
      "   macro avg       0.67      0.66      0.66       400\n",
      "weighted avg       0.80      0.81      0.80       400\n",
      "\n",
      " BoW vectorizer with GradientBoost report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.95      0.97      0.96        59\n",
      "           2       0.75      0.77      0.76        75\n",
      "           3       0.90      0.83      0.86       113\n",
      "           4       0.70      0.90      0.79       109\n",
      "           5       0.71      0.34      0.46        35\n",
      "\n",
      "    accuracy                           0.80       400\n",
      "   macro avg       0.67      0.64      0.64       400\n",
      "weighted avg       0.79      0.80      0.78       400\n",
      "\n",
      " Emb. vectorizer with GradientBoost report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.97      0.95      0.96        59\n",
      "           2       0.70      0.83      0.76        75\n",
      "           3       0.92      0.91      0.92       113\n",
      "           4       0.80      0.89      0.84       109\n",
      "           5       0.79      0.43      0.56        35\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.69      0.67      0.67       400\n",
      "weighted avg       0.82      0.83      0.82       400\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T13:38:36.345574Z",
     "start_time": "2025-09-21T13:38:36.341478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def xgboost_model(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    This model to verify the accuracy of the XGboost in classification model\n",
    "    :return: prediction, accuracy of the XGboost in classification model\n",
    "    \"\"\"\n",
    "    param_grid = {\n",
    "        \"max_depth\": 6,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"colsample_bytree\": 0.1,\n",
    "        \"reg_lambda\": 1\n",
    "        }\n",
    "    xgb = XGBClassifier(**param_grid)\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    # fit the parameters then report\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    return y_pred, score, report"
   ],
   "id": "de88c28cbb7cad23",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T13:41:32.409764Z",
     "start_time": "2025-09-21T13:38:41.851719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"XGBoost with Empirical Parameters...\")\n",
    "_, xgb_tf_accuracy, xgb_tf_report = xgboost_model(Xtrain_tfidf, Xtest_tfidf, y_train, y_test)\n",
    "_, xgb_bow_accuracy, xgb_bow_report = xgboost_model(Xtrain_bow, Xtest_bow, y_train, y_test)\n",
    "_, xgb_em_accuracy, xgb_em_report = xgboost_model(Xtrain_em, Xtest_em, y_train, y_test)\n",
    "\n",
    "print(f\" TfIdf vectorizer with XGBoost accuracy: {gb_tf_accuracy}\")\n",
    "print(f\" BoW vectorizer with XGBoost accuracy: {gb_bow_accuracy}\")\n",
    "print(f\" Emb. vectorizer with XGBoost accuracy: {gb_em_accuracy}\")"
   ],
   "id": "9c74484f7d577834",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost with Empirical Parameters...\n",
      " TfIdf vectorizer with XGBoost accuracy: 0.7875\n",
      " BoW vectorizer with XGBoost accuracy: 0.7675\n",
      " Emb. vectorizer with XGBoost accuracy: 0.8225\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![LightGBM_Core_Parameters](lightGBM_EmpiricalParameters.png)",
   "id": "b9bae361ef68c1e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T13:54:50.074115Z",
     "start_time": "2025-09-21T13:54:50.069865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def lightGBM_model(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    This model to verify the accuracy of the lightGBM in classification model\n",
    "    :return: accuracy of the lightGBM in classification model\n",
    "    \"\"\"\n",
    "    lgb_params = {\n",
    "            # Core boosting parameters\n",
    "            'n_estimators': 100,              # Good starting point, fast training\n",
    "            'learning_rate': 0.1,             # Standard learning rate\n",
    "            'max_depth': -1,                  # No limit (LightGBM uses num_leaves instead)\n",
    "            'num_leaves': 31,                 # 2^5 - 1, good default for most datasets\n",
    "\n",
    "            # Tree structure control\n",
    "            'min_child_samples': 20,          # Prevent overfitting on small datasets\n",
    "            'min_child_weight': 0.001,        # Minimum sum of hessian in child\n",
    "            'min_split_gain': 0.0,            # Minimum loss reduction for split\n",
    "\n",
    "            # Feature sampling (regularization)\n",
    "            'feature_fraction': 0.8,          # Use 80% of features per tree\n",
    "            'bagging_fraction': 0.8,          # Use 80% of data per tree\n",
    "            'bagging_freq': 5,                # Perform bagging every 5 iterations\n",
    "\n",
    "            # Regularization\n",
    "            'lambda_l1': 0.0,                 # L1 regularization\n",
    "            'lambda_l2': 0.0,                 # L2 regularization (LightGBM has natural reg)\n",
    "\n",
    "            # Performance\n",
    "            'objective': 'binary',            # Will be auto-detected for multiclass\n",
    "            'metric': 'binary_logloss',       # Will be auto-detected\n",
    "            'boosting_type': 'gbdt',          # Gradient Boosting Decision Tree\n",
    "            'verbosity': -1,                  # No output\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,                     # Use all CPU cores\n",
    "\n",
    "            # Early stopping (optional, for large datasets)\n",
    "            'early_stopping_rounds': None,   # Disabled for baseline\n",
    "            'categorical_feature': 'auto'     # Auto-detect categorical features\n",
    "        }\n",
    "    # fit model\n",
    "    lgb = LGBMClassifier(**lgb_params)\n",
    "    lgb.fit(X_train, y_train)\n",
    "\n",
    "    # prediction & export accuracy\n",
    "    y_pred = lgb.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    return y_pred, score, report"
   ],
   "id": "85f677bb39831ca0",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T13:58:57.928032Z",
     "start_time": "2025-09-21T13:56:13.439465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"lightGBM with Empirical Parameters...\")\n",
    "_, lgb_tf_accuracy, lgb_tf_report = xgboost_model(Xtrain_tfidf, Xtest_tfidf, y_train, y_test)\n",
    "_, lgb_bow_accuracy, lgb_bow_report = xgboost_model(Xtrain_bow, Xtest_bow, y_train, y_test)\n",
    "_, lgb_em_accuracy, lgb_em_report = xgboost_model(Xtrain_em, Xtest_em, y_train, y_test)\n",
    "\n",
    "print(f\" TfIdf vectorizer with lightGBM accuracy: {lgb_tf_accuracy}\")\n",
    "print(f\" BoW vectorizer with lightGBM accuracy: {lgb_bow_accuracy}\")\n",
    "print(f\" Emb. vectorizer with lightGBM accuracy: {lgb_em_accuracy}\")"
   ],
   "id": "dc49cf71a8dbb2aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightGBM with Empirical Parameters...\n",
      " TfIdf vectorizer with lightGBM accuracy: 0.8025\n",
      " BoW vectorizer with lightGBM accuracy: 0.8075\n",
      " Emb. vectorizer with lightGBM accuracy: 0.835\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fcf1ec11a909f0fd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
