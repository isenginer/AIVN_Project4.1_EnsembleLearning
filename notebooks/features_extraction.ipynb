{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# PROJECT 4.1 - ENSEMBLE LEARNING TECHNIQUE\n",
    "## `DATA COLLECTION - FEATURE EXTRACTION`\n",
    "In this Project, we shall use the ensemble learning to classify the subject & title of newspaper\n",
    "\n",
    "After clean the data, write it to dataset folder with: train, test & full dataset csv"
   ],
   "id": "5e1c0e77a34cd080"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## i_IMPORT LIBRARY",
   "id": "2d19934e8efa6b5c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-15T08:46:28.097021Z",
     "start_time": "2025-09-15T08:46:25.825232Z"
    }
   },
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils.text_preprocessing import character_preprocessing\n",
    "from utils.text_preprocessing import category_processing"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/lib/python3/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_136819/1011473003.py\", line 10, in <module>\n",
      "    from transformers.models.tapas.tokenization_tapas import parse_text\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/transformers/__init__.py\", line 27, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/transformers/utils/__init__.py\", line 24, in <module>\n",
      "    from .auto_docstring import (\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py\", line 30, in <module>\n",
      "    from .generic import ModelOutput\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/transformers/utils/generic.py\", line 53, in <module>\n",
      "    import torch  # noqa: F401\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T08:46:29.478571Z",
     "start_time": "2025-09-15T08:46:28.114424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n"
   ],
   "id": "f93aac4e9ed91e4d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T08:46:29.546248Z",
     "start_time": "2025-09-15T08:46:29.533324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ],
   "id": "9114cb3b16845fa",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. LOAD AND EXTRACT DATA\n",
    "* Dataset has been loaded into the system with location in Linux: ./home/user/.cache/huggingface/datasets\n",
    "* The dataset has been required to load at the fist time only. The second time the command will check and implement if the datasets is ready."
   ],
   "id": "c6f59050e5dba185"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T08:46:34.822344Z",
     "start_time": "2025-09-15T08:46:29.615713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ds = load_dataset(\"UniverseTBD/arxiv-abstracts-large\")\n",
    "ds"
   ],
   "id": "e9bd625873a3f959",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'submitter', 'authors', 'title', 'comments', 'journal-ref', 'doi', 'report-no', 'categories', 'license', 'abstract', 'versions', 'update_date', 'authors_parsed'],\n",
       "        num_rows: 2292057\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T08:46:34.897632Z",
     "start_time": "2025-09-15T08:46:34.886152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check asbtract of categories to see all sub-features\n",
    "# label: categories\n",
    "# features: abstract\n",
    "all_categories = ds[\"train\"][\"categories\"]\n",
    "all_abstracts = ds[\"train\"][\"abstract\"]\n",
    "print(all_categories)\n",
    "print(all_abstracts[0:1])"
   ],
   "id": "8cb63016ea7cc397",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column(['hep-ph', 'math.CO cs.CG', 'physics.gen-ph', 'math.CO', 'math.CA math.FA'])\n",
      "['  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will take 2000 samples with single label belonging to categories: [\"astro-ph\", \"cond-mat\", \"cs\", \"math\", \"physics\"]",
   "id": "5ef5957080320530"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T08:46:38.095729Z",
     "start_time": "2025-09-15T08:46:34.938868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# extract two columns for project\n",
    "ds_extracted = ds[\"train\"].select_columns([\"abstract\", \"categories\"])\n",
    "# convert to pandas & extract to csv for future use\n",
    "dataset_df = ds_extracted.to_pandas()"
   ],
   "id": "4528f02d85d9dcd5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T08:46:38.163628Z",
     "start_time": "2025-09-15T08:46:38.156835Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_df.head()",
   "id": "c8d0908dee704bcd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            abstract       categories\n",
       "0    A fully differential calculation in perturba...           hep-ph\n",
       "1    We describe a new algorithm, the $(k,\\ell)$-...    math.CO cs.CG\n",
       "2    The evolution of Earth-Moon system is descri...   physics.gen-ph\n",
       "3    We show that a determinant of Stirling cycle...          math.CO\n",
       "4    In this paper we show how to compute the $\\L...  math.CA math.FA"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>hep-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
       "      <td>math.CO cs.CG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The evolution of Earth-Moon system is descri...</td>\n",
       "      <td>physics.gen-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We show that a determinant of Stirling cycle...</td>\n",
       "      <td>math.CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In this paper we show how to compute the $\\L...</td>\n",
       "      <td>math.CA math.FA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. COLLECT REQUIRED DATA TO CSV\n",
    "From this part, the step forwards:\n",
    "* Get the first letters of categories if this letter is in [\"astro-ph\", \"cond-mat\", \"cs\", \"math\", \"physics\"]"
   ],
   "id": "bc553c43c6bc00c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T08:47:57.078119Z",
     "start_time": "2025-09-15T08:46:38.217040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_processing = dataset_df.copy()\n",
    "dataset_processing = dataset_processing.assign(\n",
    "    abstract = dataset_processing[\"abstract\"].apply(character_preprocessing),\n",
    "    categories = dataset_processing[\"categories\"].apply(category_processing)\n",
    ")\n",
    "# catetories_convert_ds = dataset_df.apply(category_processing())"
   ],
   "id": "f5ebbc2f85553f1",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T08:48:10.488037Z",
     "start_time": "2025-09-15T08:47:57.250425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features_spec = [\"astro-ph\", \"cond-mat\", \"cs\", \"math\", \"physics\"]\n",
    "# dataset_processing.to_csv(\"../dataset/full_dataset.csv\", index=False)"
   ],
   "id": "cbbe7e40e49f6084",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T08:48:10.545462Z",
     "start_time": "2025-09-15T08:48:10.543233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# creat Regrex OR by '|'\n",
    "# 'astro-ph'|'cond-mat'|'cs'|'math'|'physics'\n",
    "pattern = \"^(\" + \"|\".join(features_spec) + \")\"\n",
    "print(pattern)"
   ],
   "id": "fddd5b31a541bf7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^(astro-ph|cond-mat|cs|math|physics)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T08:48:11.075589Z",
     "start_time": "2025-09-15T08:48:10.595239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filter the DataFrame with string from full_dataset\n",
    "dataset_filtered = dataset_processing[\n",
    "    dataset_processing[\"categories\"].str.contains(pattern, case=False, na=False)\n",
    "]"
   ],
   "id": "b1c25dcf89c1ab55",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_136819/935121717.py:3: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  dataset_processing[\"categories\"].str.contains(pattern, case=False, na=False)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T08:48:11.128634Z",
     "start_time": "2025-09-15T08:48:11.090534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Collect random 2000 values from filtered dataset\n",
    "dataset_2k = dataset_filtered.sample(n=2000, random_state=42)\n",
    "dataset_2k.reset_index(drop=True, inplace=True)\n",
    "dataset_2k.head()"
   ],
   "id": "bc62a3268071500",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            abstract categories\n",
       "0  the factorially normalized bernoulli polynomia...       math\n",
       "1  we propose a simple uniform lower bound on the...       math\n",
       "2  we study truncated point schemes of connected ...       math\n",
       "3  fourdimensional d printing a new technology em...         cs\n",
       "4  we show that the dth secant variety of a proje...       math"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the factorially normalized bernoulli polynomia...</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we propose a simple uniform lower bound on the...</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we study truncated point schemes of connected ...</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fourdimensional d printing a new technology em...</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we show that the dth secant variety of a proje...</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T08:48:11.208818Z",
     "start_time": "2025-09-15T08:48:11.204263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Recheck the field is same as our requested features\n",
    "print(dataset_2k[\"categories\"].unique())"
   ],
   "id": "6a9a16601cc3b891",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['math' 'cs' 'physics' 'cond-mat' 'astro-ph' 'math-ph']\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Export to csv for future use",
   "id": "bfc3546ce5eb9c6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T08:48:23.721428Z",
     "start_time": "2025-09-15T08:48:23.710976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = dataset_2k[\"abstract\"]\n",
    "y = dataset_2k[\"categories\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Training data size: {X_train.shape}\")\n",
    "print(f\"Test data size: {X_test.shape}\")\n",
    "print(f\"Training data size: {y_train.shape}\")\n",
    "print(f\"Test data size: {y_test.shape}\")\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)"
   ],
   "id": "dbdff90c9636f6c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: (1600,)\n",
      "Test data size: (400,)\n",
      "Training data size: (1600,)\n",
      "Test data size: (400,)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T08:48:24.928396Z",
     "start_time": "2025-09-15T08:48:24.893670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_2k.to_csv(\"../dataset/dataset2k.csv\", index=False)\n",
    "train_data.to_csv(\"../dataset/train_data.csv\", index=False)\n",
    "test_data.to_csv(\"../dataset/test_data.csv\", index=False)"
   ],
   "id": "d74fbbda060d138e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8487914fb6709811"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
