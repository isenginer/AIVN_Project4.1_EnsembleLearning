{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-17T08:56:15.900492Z",
     "start_time": "2025-09-17T08:56:15.897863Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T08:56:15.951162Z",
     "start_time": "2025-09-17T08:56:15.946662Z"
    }
   },
   "cell_type": "code",
   "source": "from utils.EmbeddingVectorizer import tfidf_vectorizer, bow_vectorizer, embedding_vectorizer",
   "id": "4a066e7820ecc337",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T08:56:16.010970Z",
     "start_time": "2025-09-17T08:56:15.997053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = pd.read_csv(\"../dataset/train_data.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/test_data.csv\")\n",
    "X_train = train_data.iloc[:, 0]\n",
    "X_test = test_data.iloc[:, 0]"
   ],
   "id": "a9330decaef52ad5",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T08:56:16.423015Z",
     "start_time": "2025-09-17T08:56:16.048695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Xtrain_tfidf, Xtest_tfidf = tfidf_vectorizer(X_train=X_train, X_test=X_test)\n",
    "print(Xtrain_tfidf.shape)\n",
    "print(Xtest_tfidf.shape)"
   ],
   "id": "68327d7f10b43a64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 18450)\n",
      "(400, 18450)\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T08:56:16.607195Z",
     "start_time": "2025-09-17T08:56:16.431771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Xtrain_bow, Xtest_bow = bow_vectorizer(X_train=X_train, X_test=X_test)\n",
    "print(Xtrain_bow.shape)\n",
    "print(Xtest_bow.shape)"
   ],
   "id": "3efcf62d688af2da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 18450)\n",
      "(400, 18450)\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T08:56:16.638090Z",
     "start_time": "2025-09-17T08:56:16.635244Z"
    }
   },
   "cell_type": "code",
   "source": "Xtrain_tfidf[1][5]",
   "id": "d83800630d8e0841",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T09:00:32.027948Z",
     "start_time": "2025-09-17T08:56:21.994417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Xtrain_em, Xtest_em = embedding_vectorizer(X_train=X_train, X_test=X_test)\n",
    "print(Xtrain_em.shape)\n",
    "print(Xtest_em.shape)"
   ],
   "id": "63377dc8d23ffc54",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[33]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m Xtrain_em, Xtest_em = \u001B[43membedding_vectorizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m=\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m=\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[38;5;28mprint\u001B[39m(Xtrain_em.shape)\n\u001B[32m      3\u001B[39m \u001B[38;5;28mprint\u001B[39m(Xtest_em.shape)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/media/anhvt/DATA/10_AIO_VN/AIOVN_Main/Project 4.1_Ensemble Learning/utils/EmbeddingVectorizer.py:79\u001B[39m, in \u001B[36membedding_vectorizer\u001B[39m\u001B[34m(X_train, X_test)\u001B[39m\n\u001B[32m     72\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     73\u001B[39m \u001B[33;03mfunction to return the numpy array of train & test transformed from EmbeddingVectorizer\u001B[39;00m\n\u001B[32m     74\u001B[39m \u001B[33;03m:param X_train: train features\u001B[39;00m\n\u001B[32m     75\u001B[39m \u001B[33;03m:param X_test: test features\u001B[39;00m\n\u001B[32m     76\u001B[39m \u001B[33;03m:return: numpy array of train & test transformed from EmbeddingVectorizer\u001B[39;00m\n\u001B[32m     77\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     78\u001B[39m vectorizer = EmbeddingVectorizer()\n\u001B[32m---> \u001B[39m\u001B[32m79\u001B[39m X_train_vt = \u001B[43mvectorizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtransform_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     80\u001B[39m X_test_vt = vectorizer.transform_numpy(X_test)\n\u001B[32m     81\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m X_train_vt, X_test_vt\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/media/anhvt/DATA/10_AIO_VN/AIOVN_Main/Project 4.1_Ensemble Learning/utils/EmbeddingVectorizer.py:42\u001B[39m, in \u001B[36mEmbeddingVectorizer.transform_numpy\u001B[39m\u001B[34m(self, texts, mode)\u001B[39m\n\u001B[32m     39\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34mtransform_numpy\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[32m     40\u001B[39m                     texts: List[\u001B[38;5;28mstr\u001B[39m],\n\u001B[32m     41\u001B[39m                     mode: Literal[\u001B[33m\"\u001B[39m\u001B[33mquery\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mpassage\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[33m\"\u001B[39m\u001B[33mquery\u001B[39m\u001B[33m\"\u001B[39m) -> np.ndarray:\n\u001B[32m---> \u001B[39m\u001B[32m42\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m np.array(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/media/anhvt/DATA/10_AIO_VN/AIOVN_Main/Project 4.1_Ensemble Learning/utils/EmbeddingVectorizer.py:36\u001B[39m, in \u001B[36mEmbeddingVectorizer.transform\u001B[39m\u001B[34m(self, texts, mode)\u001B[39m\n\u001B[32m     33\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     34\u001B[39m     inputs = \u001B[38;5;28mself\u001B[39m._format_input(texts, mode)\n\u001B[32m---> \u001B[39m\u001B[32m36\u001B[39m embeddings = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalize_embeddings\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnormalize\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     37\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m embeddings.tolist()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:115\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    112\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    113\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34mdecorate_context\u001B[39m(*args, **kwargs):\n\u001B[32m    114\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m115\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/media/anhvt/DATA/_PyLIB_LINUX/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:1109\u001B[39m, in \u001B[36mSentenceTransformer.encode\u001B[39m\u001B[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001B[39m\n\u001B[32m   1107\u001B[39m             all_embeddings = np.asarray([emb.float().numpy() \u001B[38;5;28;01mfor\u001B[39;00m emb \u001B[38;5;129;01min\u001B[39;00m all_embeddings])\n\u001B[32m   1108\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1109\u001B[39m             all_embeddings = np.asarray([\u001B[43memb\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m emb \u001B[38;5;129;01min\u001B[39;00m all_embeddings])\n\u001B[32m   1110\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(all_embeddings, np.ndarray):\n\u001B[32m   1111\u001B[39m     all_embeddings = [torch.from_numpy(embedding) \u001B[38;5;28;01mfor\u001B[39;00m embedding \u001B[38;5;129;01min\u001B[39;00m all_embeddings]\n",
      "\u001B[31mRuntimeError\u001B[39m: Numpy is not available"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T08:26:53.779138Z",
     "start_time": "2025-09-17T08:26:51.720711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"Device count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")"
   ],
   "id": "53fdded21cf4e4c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.2+cu121\n",
      "CUDA available: False\n",
      "CUDA version: 12.1\n",
      "Device count: 1\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a766ebca8885519e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
